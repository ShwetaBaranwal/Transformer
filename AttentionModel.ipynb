{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AttentionModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShwetaBaranwal/Transformer/blob/master/AttentionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ40SWs8vuAH",
        "colab_type": "code",
        "outputId": "3867e1ea-3d60-46e9-a2be-7e61f21860a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!git clone https://github.com/ShwetaBaranwal/Transformer.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Transformer'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 22 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka-idSMkwd11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('./Transformer/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jneGUfplwQNr",
        "colab_type": "code",
        "outputId": "21715342-8448-44cf-8599-73e6a43353e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "from config_file import config_set\n",
        "from __future__ import unicode_literals\n",
        "import numpy as np\n",
        "from transformer import get_model, decode\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8uTkndawhQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calling configuration class\n",
        "hp = config_set()\n",
        "\n",
        "#downloading dataset\n",
        "!bash download.sh\n",
        "\n",
        "#preprocessing dataset\n",
        "!python data_load.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o83GUnvvIGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "1f07e907-c647-445d-f378-c44b2a19e9fb"
      },
      "source": [
        "print(\"Let's see how segmented data look like\")\n",
        "print(\"train1:\", open(\"iwslt2016/segmented/train.de.bpe\",'r').readline())\n",
        "print(\"train2:\", open(\"iwslt2016/segmented/train.en.bpe\", 'r').readline())\n",
        "print(\"eval1:\", open(\"iwslt2016/segmented/eval.de.bpe\", 'r').readline())\n",
        "print(\"eval2:\", open(\"iwslt2016/segmented/eval.en.bpe\", 'r').readline())\n",
        "print(\"test1:\", open(\"iwslt2016/segmented/test.de.bpe\", 'r').readline())\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's see how segmented data look like\n",
            "train1: ▁David ▁Gall o : ▁Das ▁ist ▁Bill ▁Lange . ▁Ich ▁bin ▁Dave ▁Gall o .\n",
            "\n",
            "train2: ▁David ▁Gall o : ▁This ▁is ▁Bill ▁Lange . ▁I ' m ▁Dave ▁Gall o .\n",
            "\n",
            "eval1: ▁Als ▁ich ▁11 ▁Jahre ▁alt ▁war , ▁wurde ▁ich ▁eines ▁Morgens ▁von ▁den ▁Kl ängen ▁h eller ▁Freude ▁gewe ckt .\n",
            "\n",
            "eval2: ▁When ▁I ▁was ▁11, ▁I ▁remember ▁waking ▁up ▁one ▁morning ▁to ▁the ▁sound ▁of ▁joy ▁in ▁my ▁house .\n",
            "\n",
            "test1: ▁Als ▁ich ▁in ▁meinen ▁20 ern ▁war , ▁hatte ▁ich ▁meine ▁erste ▁Psych otherapie - Pat ient in .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt8FjAm-xJ-Z",
        "colab_type": "code",
        "outputId": "261c79d1-4573-4fc2-a7f1-93d3037c25ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#importing sentencepiece tokenizor model\n",
        "import sentencepiece as spm\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(hp.embed_model)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIH_Gt5UxqmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class final_data():\n",
        "    \"\"\"\n",
        "    reads input and output document and modifies it in the form that model takes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_fpath, fpath1, fpath2, maxlen1, maxlen2):\n",
        "      \"\"\"\n",
        "      :param vocab_fpath: vocabulary file path\n",
        "      :param fpath1: source document (German)\n",
        "      :param fpath2: target document (English)\n",
        "      :param maxlen1: max sentence length of german document\n",
        "      :param maxlen2: max sentence length of english document\n",
        "      Returns\n",
        "      Intialization\n",
        "      \"\"\"\n",
        "      self.vocab_fpath = vocab_fpath\n",
        "      self.fpath1 = fpath1\n",
        "      self.fpath2 = fpath2\n",
        "      self.maxlen1 = maxlen1\n",
        "      self.maxlen2 = maxlen2\n",
        "\n",
        "\n",
        "    def load_vocab(self, vocab_path):\n",
        "      \"\"\"\n",
        "      Loads vocabulary file and returns idx<->token maps\n",
        "      :param vocab_path: (string) vocabulary file path\n",
        "      Note that these are reserved\n",
        "      0: <pad>, 1: <unk>, 2: <s>, 3: </s>\n",
        "\n",
        "      sample of vocab file:\n",
        "      <pad>\t0\n",
        "      <unk>\t0\n",
        "      <s>\t0\n",
        "      </s>\t0\n",
        "      en\t-0\n",
        "      er\t-1\n",
        "      in\t-2\n",
        "      ▁t\t-3\n",
        "      ch\t-4\n",
        "      ▁a\t-5\n",
        "      ▁d\t-6\n",
        "      ▁w\t-7\n",
        "      ▁s\t-8\n",
        "      ▁th\t-9\n",
        "      nd\t-10\n",
        "      ie\t-11\n",
        "\n",
        "      Returns\n",
        "      two dictionaries.\n",
        "      \"\"\"\n",
        "      vocab = [line.split()[0] for line in open(vocab_path, 'r').read().splitlines()]\n",
        "      token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
        "      idx2token = {idx: token for idx, token in enumerate(vocab)}\n",
        "      return token2idx, idx2token\n",
        "\n",
        "\n",
        "    def load_data(self, path1, path2, T1, T2):\n",
        "      \"\"\"\n",
        "      Loads source and target data and filters out too lengthy samples.\n",
        "      :param path1: source file path. string.\n",
        "      :param path2: target file path. string.\n",
        "      :param T1: source sent maximum length. scalar.\n",
        "      :param T2: target sent maximum length. scalar.\n",
        "      Returns\n",
        "      sents1: list of source sents\n",
        "      sents2: list of target sents\n",
        "      \"\"\"\n",
        "      sents1, sents2 = [], []\n",
        "      with open(path1, 'r') as f1, open(path2, 'r') as f2:\n",
        "          for sent1, sent2 in zip(f1, f2):\n",
        "              if len(sent1.split()) + 1 > T1: continue # 1: </s>\n",
        "              if len(sent2.split()) + 1 > T2: continue  # 1: </s>\n",
        "              sents1.append(sent1.strip())\n",
        "              sents2.append(sent2.strip())\n",
        "\n",
        "      return sents1, sents2\n",
        "\n",
        "\n",
        "    def encode(self, inp, type, dict, T1, T2):\n",
        "      \"\"\"\n",
        "      Converts string to number.\n",
        "      :param inp: input sentence tokens\n",
        "      :param type: \"x\" (source side) or \"y\" (target side)\n",
        "      :param dict: token2idx dictionary\n",
        "      :param T1: source sent maximum length. scalar.\n",
        "      :param T2: target sent maximum length. scalar.\n",
        "      Returns\n",
        "      list of numbers\n",
        "      \"\"\"\n",
        "      inp_str = str(inp)\n",
        "      if type==\"x\":\n",
        "        tokens = inp_str.split() + [\"</s>\"] + ['<pad>'] * (T1 - len(inp_str.split()) - 1)\n",
        "      else:\n",
        "        tokens = [\"<s>\"] + inp_str.split() + [\"</s>\"] + ['<pad>'] * (T2 - len(inp_str.split()) - 1)\n",
        "\n",
        "      x = [dict.get(t, dict[\"<unk>\"]) for t in tokens]\n",
        "      return x\n",
        "\n",
        "\n",
        "    def padded_array(self, sents1, sents2):\n",
        "      \"\"\"\n",
        "      Generates training / evaluation data\n",
        "      sents1: list of source sents\n",
        "      sents2: list of target sents\n",
        "      Returns\n",
        "      encoder input\n",
        "      decoder input\n",
        "      decoder output\n",
        "      \"\"\"\n",
        "      encode_input=[]\n",
        "      decode_input=[]\n",
        "      decode_output_=[]\n",
        "      self.token2idx, self.idx2token = self.load_vocab(self.vocab_fpath)\n",
        "      for sent1, sent2 in zip(sents1, sents2):\n",
        "          x = self.encode(sent1, \"x\", self.token2idx, self.maxlen1, self.maxlen2)\n",
        "          y = self.encode(sent2, \"y\", self.token2idx, self.maxlen1, self.maxlen2)\n",
        "          decoder_inp, y = y[:-1], y[1:]\n",
        "          encode_input.append(x)\n",
        "          decode_input.append(decoder_inp)\n",
        "          decode_output_.append(y)\n",
        "\n",
        "      decode_output = [list(map(lambda r: [r], r)) for r in decode_output_]\n",
        "\n",
        "      print(\"total lines in encoder input = {}\".format(len(encode_input)))\n",
        "      print(\"total lines in decoder input = {}\".format(len(decode_input)))\n",
        "      print(\"total lines in decoder output = {}\".format(len(decode_output)))\n",
        "\n",
        "      return encode_input, decode_input, decode_output\n",
        "\n",
        "\n",
        "    def compute(self):\n",
        "      \"\"\"\n",
        "      calls all definition in order\n",
        "      \"\"\"\n",
        "      xs, ys = self.load_data(self.fpath1, self.fpath2, self.maxlen1, self.maxlen2)\n",
        "      x, y_in, y_out = self.padded_array(xs, ys)\n",
        "      return x, y_in, y_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8HGUp1xxuG3",
        "colab_type": "code",
        "outputId": "9b5c9024-d1f0-431a-aac9-ccfffeaca0a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# hp.maxlen1, hp.maxlen2 = 20,20\n",
        "#calling training data\n",
        "m = final_data(hp.vocab, hp.train1, hp.train2, hp.maxlen1, hp.maxlen2)\n",
        "x, y_in, y_out = m.compute()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total lines in encoder input = 101814\n",
            "total lines in decoder input = 101814\n",
            "total lines in decoder output = 101814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihLC8DuyxwWv",
        "colab_type": "code",
        "outputId": "5c84fee1-f24f-4d45-82e2-b0b545d7033a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "x[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4416,\n",
              " 13146,\n",
              " 31931,\n",
              " 31976,\n",
              " 298,\n",
              " 100,\n",
              " 5101,\n",
              " 20907,\n",
              " 31943,\n",
              " 236,\n",
              " 862,\n",
              " 20545,\n",
              " 13146,\n",
              " 31931,\n",
              " 31943,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpr71R73xz03",
        "colab_type": "code",
        "outputId": "0960a9e6-0b10-43a4-b0a5-1da98c38fb16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "y_in[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 4416,\n",
              " 13146,\n",
              " 31931,\n",
              " 31976,\n",
              " 553,\n",
              " 96,\n",
              " 5101,\n",
              " 20907,\n",
              " 31943,\n",
              " 40,\n",
              " 31952,\n",
              " 31937,\n",
              " 20545,\n",
              " 13146,\n",
              " 31931,\n",
              " 31943,\n",
              " 3,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DvgjS5rx1fF",
        "colab_type": "code",
        "outputId": "1ff0a49c-4ded-4281-cfe3-1d2a1d14568e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "y_out[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4416],\n",
              " [13146],\n",
              " [31931],\n",
              " [31976],\n",
              " [553],\n",
              " [96],\n",
              " [5101],\n",
              " [20907],\n",
              " [31943],\n",
              " [40],\n",
              " [31952],\n",
              " [31937],\n",
              " [20545],\n",
              " [13146],\n",
              " [31931],\n",
              " [31943],\n",
              " [3],\n",
              " [0],\n",
              " [0],\n",
              " [0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czk4JP7Sr57r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6d7d3d46-290b-4944-fae1-bb7133482e26"
      },
      "source": [
        "print(np.array(x).shape)\n",
        "print(np.array(y_in).shape)\n",
        "print(np.array(y_out).shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(101814, 20)\n",
            "(101814, 20)\n",
            "(101814, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M13bUEqPx3yG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38faaef8-e7cd-4846-f7c5-b8b15e818e01"
      },
      "source": [
        "#getting model\n",
        "model = get_model(\n",
        "            token_num=len(m.token2idx),\n",
        "            embed_dim=32,\n",
        "            encoder_num=2,\n",
        "            decoder_num=2,\n",
        "            head_num=4,\n",
        "            hidden_dim=128,\n",
        "            dropout_rate=0.05,\n",
        "            use_same_embed=True,  # Use different embeddings for different languages\n",
        "        )\n",
        "\n",
        "model.compile('adam', 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Input (InputLayer)      (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Token-Embedding (EmbeddingRet)  [(None, None, 32), ( 1024000     Encoder-Input[0][0]              \n",
            "                                                                 Decoder-Input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Embedding (TrigPosEmbed (None, None, 32)     0           Token-Embedding[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, None, 32)     4224        Encoder-Embedding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, None, 32)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, None, 32)     0           Encoder-Embedding[0][0]          \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, None, 32)     64          Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, None, 32)     8352        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, None, 32)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, None, 32)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, None, 32)     64          Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, None, 32)     4224        Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, None, 32)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, None, 32)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Embedding (TrigPosEmbed (None, None, 32)     0           Token-Embedding[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, None, 32)     64          Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadSelfAttentio (None, None, 32)     4224        Decoder-Embedding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, None, 32)     8352        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadSelfAttentio (None, None, 32)     0           Decoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, None, 32)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadSelfAttentio (None, None, 32)     0           Decoder-Embedding[0][0]          \n",
            "                                                                 Decoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, None, 32)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadSelfAttentio (None, None, 32)     64          Decoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, None, 32)     64          Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadQueryAttenti (None, None, 32)     4224        Decoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadQueryAttenti (None, None, 32)     0           Decoder-1-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadQueryAttenti (None, None, 32)     0           Decoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Decoder-1-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadQueryAttenti (None, None, 32)     64          Decoder-1-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-FeedForward (FeedForw (None, None, 32)     8352        Decoder-1-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-FeedForward-Dropout ( (None, None, 32)     0           Decoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-FeedForward-Add (Add) (None, None, 32)     0           Decoder-1-MultiHeadQueryAttention\n",
            "                                                                 Decoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-FeedForward-Norm (Lay (None, None, 32)     64          Decoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadSelfAttentio (None, None, 32)     4224        Decoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadSelfAttentio (None, None, 32)     0           Decoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadSelfAttentio (None, None, 32)     0           Decoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Decoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadSelfAttentio (None, None, 32)     64          Decoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadQueryAttenti (None, None, 32)     4224        Decoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadQueryAttenti (None, None, 32)     0           Decoder-2-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadQueryAttenti (None, None, 32)     0           Decoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Decoder-2-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadQueryAttenti (None, None, 32)     64          Decoder-2-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-FeedForward (FeedForw (None, None, 32)     8352        Decoder-2-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-FeedForward-Dropout ( (None, None, 32)     0           Decoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-FeedForward-Add (Add) (None, None, 32)     0           Decoder-2-MultiHeadQueryAttention\n",
            "                                                                 Decoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-FeedForward-Norm (Lay (None, None, 32)     64          Decoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Output (EmbeddingSim)           (None, None, 32000)  32000       Decoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Token-Embedding[1][1]            \n",
            "==================================================================================================\n",
            "Total params: 1,115,392\n",
            "Trainable params: 1,115,392\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNd6owF0zPbe",
        "colab_type": "code",
        "outputId": "7a64366e-ddd9-42ee-a09b-4fcdd3e4fa38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "#model fitting\n",
        "model.fit(\n",
        "            x=[np.array(x), np.array(y_in)],\n",
        "            y=np.array(y_out),\n",
        "            epochs=10,\n",
        "            batch_size=32\n",
        "        )\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "101814/101814 [==============================] - 138s 1ms/step - loss: 4.6809\n",
            "Epoch 2/10\n",
            "101814/101814 [==============================] - 123s 1ms/step - loss: 3.6366\n",
            "Epoch 3/10\n",
            "101814/101814 [==============================] - 123s 1ms/step - loss: 3.2111\n",
            "Epoch 4/10\n",
            "101814/101814 [==============================] - 123s 1ms/step - loss: 2.9355\n",
            "Epoch 5/10\n",
            "101814/101814 [==============================] - 122s 1ms/step - loss: 2.7456\n",
            "Epoch 6/10\n",
            "101814/101814 [==============================] - 122s 1ms/step - loss: 2.6104\n",
            "Epoch 7/10\n",
            "101814/101814 [==============================] - 121s 1ms/step - loss: 2.5120\n",
            "Epoch 8/10\n",
            "101814/101814 [==============================] - 121s 1ms/step - loss: 2.4361\n",
            "Epoch 9/10\n",
            "101814/101814 [==============================] - 122s 1ms/step - loss: 2.3770\n",
            "Epoch 10/10\n",
            "101814/101814 [==============================] - 122s 1ms/step - loss: 2.3290\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a1e844a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cVkhuzJzaT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44906071-012b-4a50-e2e4-955483c7c4c3"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4wU3jL90vme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # load json and create model\n",
        "# from keras.models import model_from_json\n",
        "# json_file = open('model.json', 'r')\n",
        "# loaded_model_json = json_file.read()\n",
        "# json_file.close()\n",
        "# loaded_model = model_from_json(loaded_model_json)\n",
        "# # load weights into new model\n",
        "# loaded_model.load_weights(\"model.h5\")\n",
        "# print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DQ9TBZO0yiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c31a0fd0-68ed-4328-d125-7c393767510f"
      },
      "source": [
        "#calling evaluation/validation data\n",
        "m = final_data(hp.vocab, hp.eval1, hp.eval2, hp.maxlen1, hp.maxlen2)\n",
        "x_eval, y_in_eval, y_out_eval = m.compute()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total lines in encoder input = 487\n",
            "total lines in decoder input = 487\n",
            "total lines in decoder output = 487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtYV8HCgrl7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "345b44c5-99e8-47b7-eac9-d79a8e0517b4"
      },
      "source": [
        "print(np.array(x_eval).shape)\n",
        "print(np.array(y_in_eval).shape)\n",
        "print(np.array(y_out_eval).shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(487, 20)\n",
            "(487, 20)\n",
            "(487, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CrEsbNIrlDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd58bdca-34ee-4f23-a438-1bb3d87aa0f0"
      },
      "source": [
        "#predicting\n",
        "s_id, sentence, output_sentence = decode(\n",
        "                                    model,\n",
        "                                    x_eval,\n",
        "                                    dict_token2idx = m.token2idx,\n",
        "                                    dict_idx2token = m.idx2token,\n",
        "                                    sp = sp\n",
        "                                    )\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:15<00:00,  1.15s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2hBqPI8r3Xf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "e0c8ef02-2bc3-4209-e457-a5632fc183d2"
      },
      "source": [
        "#displaying few predicted output\n",
        "for i in range(hp.sample_num_display):\n",
        "    predicted = sentence[i]\n",
        "    actual = ' '.join(map(lambda x: m.idx2token[x], y_in_eval[i]))\n",
        "    print(\"predicted = {}\".format(predicted))\n",
        "    print(\"actual = {}\".format(actual))\n",
        "    print('\\n')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted = <s> ▁My ▁dad ▁heard ▁to ▁be ▁on ▁his ▁little ▁bit ▁of ▁the ▁Christian ▁secret ▁program . </s> <pad> <pad> <pad>\n",
            "actual = <s> ▁My ▁father ▁was ▁listening ▁to ▁BBC ▁News ▁on ▁his ▁small , ▁gray ▁radio . </s> <pad> <pad> <pad> <pad>\n",
            "\n",
            "\n",
            "predicted = <s> ▁He ▁called ▁\" We ' re ▁gone ▁out .\" </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "actual = <s> ▁\" The ▁Taliban ▁are ▁gone !\" ▁my ▁father ▁sh ou ted . </s> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "\n",
            "\n",
            "predicted = <s> ▁\" I ▁can ▁go ▁to ▁a ▁right ▁school , ▁he ▁said , ▁he ▁said . </s> <pad> <pad> <pad>\n",
            "actual = <s> ▁\" You ▁can ▁go ▁to ▁a ▁real ▁school ▁now ,\" ▁he ▁said . </s> <pad> <pad> <pad> <pad> <pad>\n",
            "\n",
            "\n",
            "predicted = <s> ▁This ▁morning ▁I ▁never ▁never ▁forgot . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "actual = <s> ▁A ▁morning ▁that ▁I ▁will ▁never ▁forget . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "\n",
            "\n",
            "predicted = <s> ▁You ' re ▁the ▁right ▁school . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "actual = <s> ▁A ▁real ▁school . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "\n",
            "\n",
            "predicted = <s> ▁It ▁could ▁go ▁so ▁both ▁for ▁school . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "actual = <s> ▁It ▁was ▁the ▁only ▁way ▁we ▁both ▁could ▁be ▁educated . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "\n",
            "\n",
            "predicted = <s> ▁Every ▁day ▁we ▁took ▁a ▁other ▁way ▁that ▁they ▁could ▁guess , ▁we ▁did . </s> <pad> <pad> <pad>\n",
            "actual = <s> ▁Each ▁day , ▁we ▁took ▁a ▁different ▁route ▁so ▁that ▁no ▁one ▁would ▁suspect ▁where ▁we ▁were ▁going .\n",
            "\n",
            "\n",
            "predicted = <s> ▁We ' re ▁going ▁to ▁say , ▁we ▁were ▁in ▁a ▁house ▁on ▁100 ▁girls ▁in ▁a ▁little ▁room\n",
            "actual = <s> ▁The ▁school ▁was ▁in ▁a ▁house , ▁more ▁than ▁100 ▁of ▁us ▁packed ▁in ▁one ▁small ▁living ▁room .\n",
            "\n",
            "\n",
            "predicted = <s> ▁In ▁winter , ▁it ▁was ▁a ▁sales , ▁but ▁in ▁summer , ▁it ▁was ▁incredibly ▁hot . </s> <pad>\n",
            "actual = <s> ▁It ▁was ▁co zy ▁in ▁winter ▁but ▁extremely ▁hot ▁in ▁summer . </s> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "\n",
            "\n",
            "predicted = <s> ▁We ▁all ▁knew ▁we ▁knew ▁our ▁life , ▁teacher , ▁teachers , ▁students ▁and ▁our ▁parents . </s> <pad>\n",
            "actual = <s> ▁We ▁all ▁knew ▁we ▁were ▁risk ing ▁our ▁lives ▁-- ▁the ▁teacher , ▁the ▁students ▁and ▁our ▁parents .\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0gSAznPsA_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#writing predicted output in file\n",
        "with open(hp.predicted_output_file, \"w\") as fout:\n",
        "    for sent in output_sentence:\n",
        "        fout.write(sent + \"\\n\")\n",
        "\n",
        "#writing actual output in file\n",
        "with open(hp.actual_output_file, \"w\") as fout:\n",
        "    for sent in y_in_eval:\n",
        "      s1 = list(map(lambda x: m.idx2token[x], sent))\n",
        "      s2 = ' '.join(i.replace('▁','') for i in s1 if i not in ('<s>','</s>','<pad>'))\n",
        "      fout.write(s2 + \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDCLzIUbsMcd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "aa7ada4a-c15b-4848-d556-c1f1857273e7"
      },
      "source": [
        "#computing BLEU score for validation data\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "score = []\n",
        "with open(hp.actual_output_file, 'r') as f1, open(hp.predicted_output_file, 'r') as f2:\n",
        "    for actual, predict in zip(f1, f2):\n",
        "        reference = actual.split()\n",
        "        candidate = predict.split()\n",
        "        score.append(sentence_bleu(reference, candidate))\n",
        "print(\"Avg Bleu score for document is: {}\".format(float(sum(score)/len(score))))\n",
        "print(\"Min Bleu score for document is: {}\".format(float(min(score))))\n",
        "print(\"Max Bleu score for document is: {}\".format(float(max(score))))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg Bleu score for document is: 0.22658467412289496\n",
            "Min Bleu score for document is: 0.0\n",
            "Max Bleu score for document is: 0.8408964152537145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG0uqSzosOL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "12f6f189-fb9e-4bb2-e6bb-d17561a05f77"
      },
      "source": [
        "#plotting bleu score distribution\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data = np.array(score)\n",
        "\n",
        "# fixed bin size\n",
        "bins = np.arange(0.0,1.0,0.1) # fixed bin size\n",
        "\n",
        "plt.xlim([min(data), max(data)])\n",
        "\n",
        "plt.hist(data, bins=bins, alpha=0.5)\n",
        "plt.title('Bleu score distribution')\n",
        "plt.xlabel('Bleu score')\n",
        "plt.ylabel('count')\n",
        "plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgDJ9_JjsSMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "83c319b5-31bf-41b6-d64e-a98d2e2fd37f"
      },
      "source": [
        "#calling test data\n",
        "m = final_data(hp.vocab, hp.test1, hp.test1, hp.maxlen1, hp.maxlen2)\n",
        "x_test, _, _ = m.compute()\n",
        "\n",
        "#predicting\n",
        "s_id_test, sentence_test, output_sentence_test = decode(\n",
        "                                          model,\n",
        "                                          x_test,\n",
        "                                          dict_token2idx = m.token2idx,\n",
        "                                          dict_idx2token = m.idx2token,\n",
        "                                          sp = sp\n",
        "                                          )\n",
        "\n",
        "#writing predicted output in file\n",
        "with open(hp.test_output_file, \"w\") as fout:\n",
        "    for sent in output_sentence_test:\n",
        "        fout.write(sent + \"\\n\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total lines in encoder input = 724\n",
            "total lines in decoder input = 724\n",
            "total lines in decoder output = 724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19/19 [00:20<00:00,  1.72s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQxv_-r2sehK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}